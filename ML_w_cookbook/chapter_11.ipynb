{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import KFold, cross_val_score \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_diabetes, load_iris, make_classification\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9699472377405337)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11.1 Cross-validating models\n",
    "digits = datasets.load_digits()\n",
    "features = digits.data \n",
    "target = digits.target \n",
    "standardizer = StandardScaler()\n",
    "logit = LogisticRegression()\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "kf = KFold(n_splits=10, shuffle = True, random_state = 1)\n",
    "cv_results = cross_val_score(pipeline, \n",
    "                            features, \n",
    "                            target, \n",
    "                            cv = kf, \n",
    "                            scoring = \"accuracy\", \n",
    "                            n_jobs = -1)\n",
    "\n",
    "cv_results.mean()\n",
    "\n",
    "# kfold cross-validation\n",
    "# we split the data intro k parts called folds\n",
    "# The model is then trained suing k - 1 folds - combined into training set - and then \n",
    "# the last fold as the test set \n",
    "# The performance on the model for each of the k oiterations is then averaged to produce an \n",
    "# overall measurement.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98888889, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # important points:\n",
    "# 1. Assume each observation was created independent from the others (IID)\n",
    "\n",
    "# 2. when we use KFCV to evaluate a classifier, it is often beneficial to have folds \n",
    "# containing roughly the same percentage of observations from each of the different \n",
    "# target classes (stratified cross-validation)\n",
    "\n",
    "# 3. when using validation sets or cross-validation, it is important to preprocess \n",
    "# data based on the training set and then apply those transformations to both \n",
    "# the training and test sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "                                                                            target, \n",
    "                                                                            test_size=0.1, \n",
    "                                                                            random_state = 1)\n",
    "standardizer.fit(features_train)\n",
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(standardizer, logit)\n",
    "cv_results = cross_val_score(pipeline, \n",
    "                             features, \n",
    "                             target, \n",
    "                             cv=kf, \n",
    "                             scoring=\"accuracy\", \n",
    "                             n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98888889, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007035918242200845"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11.2 creating a baseline regression model \n",
    "diabetes = load_diabetes()\n",
    "features, target = diabetes.data, diabetes.target \n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, random_state = 1)\n",
    "\n",
    "dummy = DummyRegressor(strategy=\"mean\")\n",
    "dummy.fit(features_train, target_train)\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4439690125828355"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to compare, we trian our model and evaluate the performance score \n",
    "ols = LinearRegression() \n",
    "ols.fit(features_train, target_train)\n",
    "\n",
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.1181539467984978"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DummyRegressor(strategy=\"constant\", constant=20)\n",
    "clf.fit(features_train, target_train)\n",
    "clf.score(features_test, target_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/r_square.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34210526315789475"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11.3 Creating a baseline classification Model \n",
    "iris = load_iris() \n",
    "features, target = iris.data, iris.target \n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, random_state = 0\n",
    ")\n",
    "\n",
    "clf = DummyClassifier(strategy=\"uniform\")\n",
    "clf.fit(features_train, target_train)\n",
    "clf.score(features_test, target_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(features_train, target_train)\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9322 , 0.933  , 0.9359 , 0.93375, 0.93705])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11.4 Evaluating Binary Classifer Predictions \n",
    "x,y = make_classification(n_samples = 100000, \n",
    "                          n_features=3, \n",
    "                          n_informative = 3, \n",
    "                          n_redundant = 0, \n",
    "                          n_classes = 2, \n",
    "                          random_state = 1)\n",
    "logit = LogisticRegression()\n",
    "cross_val_score(logit, x, y, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/accuracy.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9555, 0.95  , 0.9585, 0.9555, 0.956 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = make_classification(n_samples = 10000, \n",
    "                           n_features = 3, \n",
    "                           n_informative = 3, \n",
    "                           n_redundant = 0, \n",
    "                           n_classes = 2, \n",
    "                           random_state = 1)\n",
    "logit = LogisticRegression() \n",
    "cross_val_score(logit, x, y, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95963673, 0.94820717, 0.9635996 , 0.96149949, 0.96060606])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, x, y, scoring=\"precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/precision.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.951, 0.952, 0.953, 0.949, 0.951])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, x, y, scoring=\"recall\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/recall_1.png\">\n",
    "<img src=\"./assets/recall_2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95529884, 0.9500998 , 0.95827049, 0.95520886, 0.95577889])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, x, y, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/f1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
